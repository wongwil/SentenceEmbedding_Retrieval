{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b879cf96-a01b-4d4b-94b5-828939d926f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                article  \\\n",
      "0     THE GIRL IN HIS MIND\\nBy ROBERT F. YOUNG\\n\\n\\n...   \n",
      "1     THE GIRL IN HIS MIND\\nBy ROBERT F. YOUNG\\n\\n\\n...   \n",
      "2     THE GIRL IN HIS MIND\\nBy ROBERT F. YOUNG\\n\\n\\n...   \n",
      "3     THE GIRL IN HIS MIND\\nBy ROBERT F. YOUNG\\n\\n\\n...   \n",
      "4     THE GIRL IN HIS MIND\\nBy ROBERT F. YOUNG\\n\\n\\n...   \n",
      "...                                                 ...   \n",
      "2081  The end of the web\\nIn the past year, as we ha...   \n",
      "2082  The end of the web\\nIn the past year, as we ha...   \n",
      "2083  The end of the web\\nIn the past year, as we ha...   \n",
      "2084  The end of the web\\nIn the past year, as we ha...   \n",
      "2085  The end of the web\\nIn the past year, as we ha...   \n",
      "\n",
      "                                               question  \\\n",
      "0     How much time has passed between Blake's night...   \n",
      "1     Why does Deirdre get so upset when Blake Past ...   \n",
      "2     Why does shame flame in Blake's cheeks when De...   \n",
      "3     Why did Blake create the three female super-im...   \n",
      "4                                      Sabrina York is    \n",
      "...                                                 ...   \n",
      "2081                           The author of this piece   \n",
      "2082                               The author is afraid   \n",
      "2083                 What is ironic about the internet?   \n",
      "2084        One way the internet is damaging society is   \n",
      "2085  According to the author, who should govern the...   \n",
      "\n",
      "                                                options  gold_label  \n",
      "0                 [7 years, 10 hours, 12 years, 1 hour]           2  \n",
      "1     [Because Blake is trying to guilt Deirdre into...           2  \n",
      "2     [He is embarrassed at the thought that Deirdre...           3  \n",
      "3     [He feels guilty about having slept with Eldor...           4  \n",
      "4     [a criminal that Blake is hunting, a psycheye ...           1  \n",
      "...                                                 ...         ...  \n",
      "2081  [has radical ideas concerning how the internet...           4  \n",
      "2082  [that the dark web is going to cause long-last...           4  \n",
      "2083  [It was never meant to be such a huge part of ...           2  \n",
      "2084  [by allowing social media to overtake the live...           2  \n",
      "2085  [The \"Big Four\", Individual governments., The ...           4  \n",
      "\n",
      "[2086 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "# ds_dev = load_from_disk('datasets/quality/dev') # doesn't work anymore..\n",
    "\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "questionlist = []\n",
    "# Open the JSON file\n",
    "with open('datasets/quality/raw/QuALITY.v1.0.1.htmlstripped.dev', 'r') as file:\n",
    "    # Load the JSON data\n",
    "    for line in file:\n",
    "      line = line.strip()\n",
    "\n",
    "      json_obj = json.loads(line)\n",
    "\n",
    "      article = json_obj['article']\n",
    "      \n",
    "      for jquestion in json_obj['questions']:\n",
    "        # getting the relevant properties\n",
    "        row = {'article': article, 'question': jquestion['question'], 'options': jquestion['options'], 'gold_label': jquestion['gold_label']}\n",
    "        questionlist.append(row)\n",
    "\n",
    "# turn it into hugging face dataset\n",
    "df = pd.DataFrame(questionlist)\n",
    "print(df)\n",
    "\n",
    "ds_dev = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f154abc-9ad5-4c02-ac04-d9f433477512",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b822054-02a9-4b14-a61a-ec0af53a890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaLarge() # automaize\n",
    "model_name = \"Roberta\" # CHANGE THIS FOR OUTPUT FILES\n",
    "max_length = model.get_max_seq_length()\n",
    "tokenizer = model.get_tokenizer()\n",
    "\n",
    "token_size = 32 # experiment size we have 64, 128 or 256\n",
    "model.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da30f0ab-97f7-4ebf-8a44-d3ea42a85d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectTopChunks(embeddings_df, row, model):\n",
    "    question = row['question']\n",
    "    options = row['options']\n",
    "    extra_length = model.get_extra_input_length(question=question, options=options)\n",
    "    \n",
    "    max_length = model.get_max_seq_length()\n",
    "    MAX_TOKEN_SIZE = max_length - extra_length\n",
    "    \n",
    "    #print(question)\n",
    "    embeddings_sorted = embeddings_df.sort_values(by=['sim_score'], ascending=False) # sort by similarity score\n",
    "    top_chunks = []\n",
    "    token_ctr = 0\n",
    "    for index, row in embeddings_sorted.iterrows():\n",
    "        chunk_text = row['chunk_text']\n",
    "        chunk_token_size = len(tokenizer.tokenize(chunk_text))\n",
    "        if (token_ctr+chunk_token_size) > MAX_TOKEN_SIZE:\n",
    "            break\n",
    "        else:\n",
    "            top_chunks.append((index, chunk_text))\n",
    "            token_ctr += chunk_token_size\n",
    "\n",
    "\n",
    "    top_chunks = sorted(top_chunks, key=lambda tup: tup[0]) # sort by chunk_id => original order\n",
    "\n",
    "    return top_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46b1a518-eb99-4ec4-8162-08f98bf06629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "[(1616, '\"That night we asked them to sleep with us in the caves, but they made camp in the valley instead. The darkness passed swiftly and silently, and with the dawn we left our caves to rejoin our new friends. But everywhere a red man showed himself, he cried out and died by the flame from the white men\\'s weapons. \"I looked into the valley and saw hundreds of Oan. They had captured our friends in the night and were using their weapons to attack us. There was a one-sided battle that lasted three days. Finally, under cover of night, we were forced to leave the caves. One by one we went, and those of us who lived still travel alone.\" Ro groaned aloud as Na finished her tale. His homecoming was a meeting with tragedy, instead of a joyful occasion. \"What of my father?\" he asked hopefully. \"He was a great warrior. Surely he didn\\'t fall to the Oan?\" \"He had no chance to fight,\" Na answered. \"Two of your brothers died with him on that first morning.\"Ro squared his shoulders and set his jaw. He wiped a hint of tears from his eyes. \"They shall pay,\" he murmured, and started off toward the cliffs again. Na trailed behind him. Her face was grave with concern. \"They are very many,\" she said. \"Then there will be more to kill,\" answered Ro without turning. \"They have the weapons of the white ones.\" \"And the white ones, as well. ')]\n"
     ]
    }
   ],
   "source": [
    "# test for single question\n",
    "idx = 85\n",
    "item = ds_dev[idx]\n",
    "\n",
    "question = item[\"question\"]\n",
    "options = item[\"options\"]\n",
    "label = item[\"gold_label\"] - 1\n",
    "\n",
    "df_embeddings = pd.read_pickle('Chunkscores_tokensize_256.pickle')\n",
    "embeddings = df_embeddings.loc[df_embeddings['article_id']== idx]\n",
    "\n",
    "selectedTopChunks = selectTopChunks(embeddings, item, model) # list of tuples (id, text)\n",
    "\n",
    "input_text = \"\".join([tup[1] for tup in selectedTopChunks]) # merge chunks as string\n",
    "\n",
    "\n",
    "prediction = -1\n",
    "with torch.no_grad():\n",
    "    prediction = model.predict(context=input_text, question=question, options=options)\n",
    "\n",
    "print(prediction)\n",
    "print(label)\n",
    "print(selectedTopChunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61d92725-74d3-401e-bc1a-1add2735291e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/2086\n",
      "100/2086\n",
      "200/2086\n",
      "300/2086\n",
      "400/2086\n",
      "500/2086\n",
      "600/2086\n",
      "700/2086\n",
      "800/2086\n",
      "900/2086\n",
      "1000/2086\n",
      "1100/2086\n",
      "1200/2086\n",
      "1300/2086\n",
      "1400/2086\n",
      "1500/2086\n",
      "1600/2086\n",
      "1700/2086\n",
      "1800/2086\n",
      "1900/2086\n",
      "2000/2086\n"
     ]
    }
   ],
   "source": [
    "# RUN PREDICTIONS\n",
    "\n",
    "# NOTE: to run the predictions, the sentence embeddings need to be saved as a pickle file. Either run CreateSentEmbeddings.ipynb to create the sentence embeddings\n",
    "# or load them during runtime (not recommended)\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error() # remove warnings\n",
    "df_embeddings = pd.read_pickle(f'Chunkscores_tokensize_{str(token_size)}.pickle')\n",
    "experiment_dict = {'predictions': [], 'labels': [], 'selected_chunk_ids': []}\n",
    "for item_id in range(0, len(ds_dev)):\n",
    "    item = ds_dev[item_id]\n",
    "\n",
    "    question = item[\"question\"]\n",
    "    options = item[\"options\"]\n",
    "    label = item[\"gold_label\"] - 1\n",
    "\n",
    "    embeddings = df_embeddings.loc[df_embeddings['article_id'] == item_id]\n",
    "\n",
    "    selectedTopChunks = selectTopChunks(embeddings, item, model) # list of tuples (id, text)\n",
    "\n",
    "    input_text = \"\".join([tup[1] for tup in selectedTopChunks]) # merge chunks as string\n",
    "    selected_chunk_ids = [tup[0] for tup in selectedTopChunks] # get all chunk_ids that were selected for analysis\n",
    "    prediction = -1\n",
    "    with torch.no_grad():\n",
    "        prediction = model.predict(context=input_text, question=question, options=options)\n",
    "\n",
    "    experiment_dict['predictions'].append(prediction)\n",
    "    experiment_dict['labels'].append(label)\n",
    "    experiment_dict['selected_chunk_ids'].append(selected_chunk_ids)\n",
    "\n",
    "    if (item_id) % 100 == 0: #output\n",
    "        print(f\"{item_id}/{len(ds_dev)}\")\n",
    "\n",
    "experiment_df = pd.DataFrame.from_dict(experiment_dict)\n",
    "experiment_df.to_csv(f'experiment_sentembb_{str(token_size)}_{str(model_name)}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4d0a65-d286-4ca6-bf5d-e05c45459b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = model.get_tokenizer()\n",
    "\n",
    "embeddings_sorted = df_embeddings.loc[df_embeddings['article_id']==0].sort_values(by=['sim_score'], ascending=False)\n",
    "\n",
    "top_chunks = [] # list of tuples (chunk_id, chunk_text)\n",
    "\n",
    "token_ctr = 0\n",
    "for index, row in embeddings_sorted.iterrows():\n",
    "    chunk_text = row['chunk_text']\n",
    "    chunk_token_size = len(tokenizer.tokenize(chunk_text))\n",
    "    if (token_ctr+chunk_token_size) > MAX_TOKEN_SIZE:\n",
    "        break\n",
    "    else:\n",
    "        top_chunks.append((index, chunk_text))\n",
    "        token_ctr += chunk_token_size\n",
    "        \n",
    "        \n",
    "top_chunks = sorted(top_chunks, key=lambda tup: tup[0]) # sort by chunk_id => original order\n",
    "\n",
    "print(top_chunks)\n",
    "print(model.get_max_seq_length())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d137e194-6faf-4af2-b943-da20090cbdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df.to_csv(f'experiment_sentembb_{str(token_size)}_{str(\"Roberta\")}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "107d5c8a-bfb1-46a8-afec-5d4be1c79524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.5311601150527325}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import evaluate\n",
    "\n",
    "experiment_df1 = pd.read_csv(f'experiment_sentembb_32_Roberta.csv')\n",
    "preds = experiment_df1['predictions'].values.tolist()\n",
    "labels = experiment_df1['labels'].values.tolist()\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "metric = accuracy.compute(references=labels, predictions=preds)\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174f2e79-b190-4b4f-82eb-bc4b37d55cec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
