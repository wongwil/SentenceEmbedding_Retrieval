{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install datasets evaluate\n",
        "!pip install --upgrade accelerate\n",
        "!pip install transformers==4.28.0\n",
        "!pip install --upgrade huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from transformers import BertTokenizer, AutoTokenizer, AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
        "from transformers.utils import logging\n",
        "import os\n",
        "from datasets import load_dataset, Dataset, load_from_disk\n",
        "from huggingface_hub import login\n",
        "from dataclasses import dataclass\n",
        "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from typing import Optional, Union\n",
        "import torch\n",
        "import json\n",
        "import pandas as pd\n",
        "import random\n",
        "from baseline_retrieval import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdcHq0AngIOM",
        "outputId": "33706058-d09d-4b48-8b42-c9548414a5fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "destination folder exists already\n"
          ]
        }
      ],
      "source": [
        "# login to huggingface hub\n",
        "login(token=\"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\")\n",
        "\n",
        "# NOTE: this part is not needed if not running on collab\n",
        "drive.mount('/content/drive') \n",
        "\n",
        "# NOTE: navigate to the folder with dataset\n",
        "folder = '/content/drive/My Drive/CSNLP' \n",
        "os.chdir(folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_train = load_from_disk('datasets/quality/train')\n",
        "ds_dev = load_from_disk('datasets/quality/dev')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WGhbA5aFqYXh"
      },
      "outputs": [],
      "source": [
        " tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\") # REPLACE if we decide to use another model\n",
        " MAX_TOKENS = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UzxkxEnhvhP",
        "outputId": "ba31b373-0b03-4345-acdc-26963fcd57f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                article  \\\n",
            "0     Therefore, even assuming\\n that Blake was less...   \n",
            "1     Therefore, even assuming\\n that Blake was less...   \n",
            "2     Therefore, even assuming\\n that Blake was less...   \n",
            "3     Therefore, even assuming\\n that Blake was less...   \n",
            "4     Therefore, even assuming\\n that Blake was less...   \n",
            "...                                                 ...   \n",
            "2081  After almost 20 years of bickering and interna...   \n",
            "2082  After almost 20 years of bickering and interna...   \n",
            "2083  After almost 20 years of bickering and interna...   \n",
            "2084  After almost 20 years of bickering and interna...   \n",
            "2085  After almost 20 years of bickering and interna...   \n",
            "\n",
            "                                               question  \\\n",
            "0     How much time has passed between Blake's night...   \n",
            "1     Why does Deirdre get so upset when Blake Past ...   \n",
            "2     Why does shame flame in Blake's cheeks when De...   \n",
            "3     Why did Blake create the three female super-im...   \n",
            "4                                      Sabrina York is    \n",
            "...                                                 ...   \n",
            "2081                           The author of this piece   \n",
            "2082                               The author is afraid   \n",
            "2083                 What is ironic about the internet?   \n",
            "2084        One way the internet is damaging society is   \n",
            "2085  According to the author, who should govern the...   \n",
            "\n",
            "                                                options  gold_label  \n",
            "0                 [7 years, 10 hours, 12 years, 1 hour]           2  \n",
            "1     [Because Blake is trying to guilt Deirdre into...           2  \n",
            "2     [He is embarrassed at the thought that Deirdre...           3  \n",
            "3     [He feels guilty about having slept with Eldor...           4  \n",
            "4     [a criminal that Blake is hunting, a psycheye ...           1  \n",
            "...                                                 ...         ...  \n",
            "2081  [has radical ideas concerning how the internet...           4  \n",
            "2082  [that the dark web is going to cause long-last...           4  \n",
            "2083  [It was never meant to be such a huge part of ...           2  \n",
            "2084  [by allowing social media to overtake the live...           2  \n",
            "2085  [The \"Big Four\", Individual governments., The ...           4  \n",
            "\n",
            "[2086 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "path = 'dataset/QuALITY.v1.0.1.htmlstripped.dev' # where the data files are located\n",
        "questionlist = []\n",
        "# Open the JSON file\n",
        "with open(path, 'r') as file:\n",
        "    # Load the JSON data\n",
        "    for line in file:\n",
        "      line = line.strip()\n",
        "\n",
        "      json_obj = json.loads(line)\n",
        "\n",
        "      article = json_obj['article']\n",
        "\n",
        "      # TODO: change depending on experiment\n",
        "      article = random_sentence_cut(article)\n",
        "      \n",
        "      for jquestion in json_obj['questions']:\n",
        "        # getting the relevant properties\n",
        "        row = {'article': article, 'question': jquestion['question'], 'options': jquestion['options'], 'gold_label': jquestion['gold_label']}\n",
        "        questionlist.append(row)\n",
        "\n",
        "df = pd.DataFrame(questionlist)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NdgXNqsiJsO",
        "outputId": "c6c51625-ef89-49ba-b5cb-c1f9b013e3b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6FpZXEHiEsP",
        "outputId": "0ac73bca-814c-4c99-f22b-4f06f3c3516c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "512\n"
          ]
        }
      ],
      "source": [
        "# example of converting it into hugging face dataset \n",
        "from datasets import Dataset\n",
        "dataset = Dataset.from_pandas(df, split='dev')\n",
        "\n",
        "# check number of tokens\n",
        "print(len(tokenizer.tokenize(dataset[0]['article'])))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
